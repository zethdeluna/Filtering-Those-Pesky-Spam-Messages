{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Those Pesky Spam Messages\n",
    "_Author: Zeth De Luna &mdash; September 5, 2020_\n",
    "\n",
    "In this project, we're going to study the practical side of the Naive Bayes algorithm by building a spam filter for SMS messages.\n",
    "\n",
    "To classify messages as spam or non-spam, the computer:\n",
    "1. Learns how humans classify messages.\n",
    "2. Uses that human knowledge to estimate probabilities for new messages &mdash; probabilities for spam and non-spam.\n",
    "3. Classifies a new message based on these probability values &mdash; if the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, we may need a human to classify the message).\n",
    "\n",
    "Our first task is to \"teach\" the computer how to classify messages. To do this, we'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans.\n",
    "\n",
    "The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, which can be downloaded from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
    "\n",
    "## Exploring the Data\n",
    "Let's read in the data and get familiar with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_collection = pd.read_csv('SMSSpamCollection', sep='\\t', header=None,\n",
    "                              names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 5572\n",
      "Number of Columns: 2\n"
     ]
    }
   ],
   "source": [
    "print('Number of Rows: {}'.format(spam_collection.shape[0]))\n",
    "print('Number of Columns: {}'.format(spam_collection.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_collection['Label'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SMSSpamCollection` data set has 5,572 rows (each row contains information on a single message) and has no empty rows. We see that the `Label` column can be either `ham` or `spam`. Given that this data set is about messages that were classified either as spam or non-spam, we can infer that `ham` refers to non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data set is:\n",
      "86.59% ham messages\n",
      "13.41% spam messages\n"
     ]
    }
   ],
   "source": [
    "n_ham = spam_collection['Label'].value_counts()[0]\n",
    "n_spam = spam_collection['Label'].value_counts()[1]\n",
    "n_total = spam_collection.shape[0]\n",
    "\n",
    "percent_ham = (n_ham / n_total) * 100\n",
    "percent_spam = (n_spam / n_total) * 100\n",
    "print('This data set is:\\n{:.2f}% ham messages\\n{:.2f}% spam messages'\n",
    "      .format(percent_ham, percent_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this data set consists mostly of non-spam messages.\n",
    "\n",
    "## Creating a Training and Test Set\n",
    "Before we actually use our spam filter, we should first test it to see if it works. So, we're going to split the data set into two categories:\n",
    "* A training set, which we'll use to \"train\" the computer how to classify messages.\n",
    "* A test set, which we'll use to test how good the spam filter is with classifying new messages.\n",
    "\n",
    "We're going to keep 80% of our data set for training, and 20% for testing, i.e.:\n",
    "* The training set will have 4,458 messages (about 80% of the data).\n",
    "* The test set will have 1,114 messages (about 20% of the data).\n",
    "\n",
    "When the spam filter is ready, we're going to treat the test set as new messages and have the filter classify them. Then, we'll compare the results of the algorithm classification with the classification done by a human and see how well the filter performed. Let's set our bar at 80% accuracy &mdash; we'll conclude that the spam filter works if it can correctly classify (spam or ham) at least 80% of the messages.\n",
    "\n",
    "First, we'll randomize our entire data set, then assign 80% of it to the training set and the remaining 20% to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the data\n",
    "randomized = spam_collection.sample(frac=1, random_state=1)\n",
    "\n",
    "# create training and test data sets\n",
    "training_set = (randomized.iloc[:4458, :]\n",
    "                    .copy()\n",
    "                    .reset_index(drop=True)\n",
    "               )\n",
    "\n",
    "test_set = (randomized.iloc[4458:, :]\n",
    "                .copy()\n",
    "                .reset_index(drop=True)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set shape: (4458, 2)\n",
      "Test Set shape: (1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# check shape of both data sets\n",
    "print('Training Set shape: {}'.format(training_set.shape))\n",
    "print('Test Set shape: {}'.format(test_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of the training set and test set look good. Let's find the percentage of spam and ham messages in both of these sets. Hopefully, they'll be representative of the original data set, `spam_collection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            SMS\n",
       "0   ham                   Yep, by the pretty sculpture\n",
       "1   ham  Yes, princess. Are you going to make me moan?"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3858\n",
       "spam     600\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     967\n",
       "spam    147\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "86.54% ham messages\n",
      "13.46% spam messages\n",
      "\n",
      "Test Set:\n",
      "86.80% ham messages\n",
      "13.20% spam messages\n"
     ]
    }
   ],
   "source": [
    "# spam and ham percentages for the training set\n",
    "n_ham_training = training_set['Label'].value_counts()[0]\n",
    "n_spam_training = training_set['Label'].value_counts()[1]\n",
    "perc_ham_training = (n_ham_training / training_set.shape[0]) * 100\n",
    "perc_spam_training = (n_spam_training / training_set.shape[0]) * 100\n",
    "\n",
    "n_ham_test = test_set['Label'].value_counts()[0]\n",
    "n_spam_test = test_set['Label'].value_counts()[1]\n",
    "perc_ham_test = (n_ham_test / test_set.shape[0]) * 100\n",
    "perc_spam_test = (n_spam_test / test_set.shape[0]) * 100\n",
    "\n",
    "print('Training Set:\\n{:.2f}% ham messages\\n{:.2f}% spam messages'\n",
    "     .format(perc_ham_training, perc_spam_training))\n",
    "print('')\n",
    "print('Test Set:\\n{:.2f}% ham messages\\n{:.2f}% spam messages'\n",
    "     .format(perc_ham_test, perc_spam_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test sets both have ham-vs-spam percentages that are very similar to the original data set. These data sets would be sufficient for training and testing our spam filter.\n",
    "\n",
    "## Cleaning the Training Data\n",
    "Recall that we'll be using the Naive Bayes algorithm to calculate the probability that a message will be spam or ham. When a message is entered into the algorithm, it will make the classification based on the results it gets to the equations below:\n",
    "\n",
    "$$ P(\\textrm{Spam}|w_1,w_2,\\ldots,w_n) \\propto P(\\textrm{Spam}) \\cdot \\prod_{i=1}^{n} P(w_i|\\textrm{Spam}) $$\n",
    "\n",
    "$$ P(\\textrm{Ham}|w_1,w_2,\\ldots, w_n) \\propto P(\\textrm{Ham}) \\cdot \\prod_{i=1}^{n} P(w_i|\\textrm{Ham}) $$\n",
    "\n",
    "Where $P(w_i|\\textrm{Spam})$ and $P(w_i|\\textrm{Ham})$ are given by:\n",
    "\n",
    "$$ P(w_i|\\textrm{Spam}) = \\frac{N_{w_i|\\textrm{Spam}} + \\alpha}{N_{\\textrm{Spam}} + \\alpha \\cdot N_{\\textrm{Vocabulary}}} $$\n",
    "\n",
    "$$ P(w_i|\\textrm{Ham}) = \\frac{N_{w_i|\\textrm{Ham}} + \\alpha}{N_{\\textrm{Ham}} + \\alpha \\cdot N_{\\textrm{Vocabulary}}} $$\n",
    "\n",
    "Equation Terms:\n",
    "* $N_{w_i|\\textrm{Spam}}$ &mdash; the number of times the word $w_i$ occurs in spam messages\n",
    "* $N_{w_i|\\textrm{Spam}^C}$ &mdash; the number of times the word $w_i$ occurs in non-spam messages\n",
    "* $N_{\\textrm{Spam}}$ &mdash; total number of words in spam messages\n",
    "* $N_{\\textrm{Spam}^C}$ &mdash; total number of words in non-spam messages\n",
    "* $N_{\\textrm{Vocabulary}}$ &mdash; total number of words in the vocabulary\n",
    "* $\\alpha = 1$ ($\\alpha$ is a smoothing parameter)\n",
    "\n",
    "Before we can apply these equations to our data, we'll need to do some cleaning to bring the data in a format that will allow us to extract easily all the information we need. For our purposes, the easiest format would result in the table below.\n",
    "\n",
    "|  | Label | $w_1$ | $w_2$ | $\\ldots$ | $w_n$ |\n",
    "|--|-------|-------|-------|----------|-------|\n",
    "| 0| spam  |   2   |   4   | $\\ldots$ |   1   |\n",
    "| 1| ham   |   1   |   0   | $\\ldots$ |   0   |\n",
    "| 2| spam  |   3   |   1   | $\\ldots$ |   2   |\n",
    "\n",
    "To do this, we'll:\n",
    "* Replace the `SMS` column with a series of new columns, where each column represents a unique word from the vocabulary.\n",
    "* Each row describes a single message.\n",
    "* All words in the vocabulary are lower case, so our comparisons should be case-insensitive.\n",
    "* Punctuation is not taken into account anymore.\n",
    "\n",
    "We'll begin by removing the punctuation from the messages and converting all letters to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all punctuation from the SMS column in the training set\n",
    "# and transform all letters to lower case\n",
    "training_set['SMS'] = (training_set['SMS']\n",
    "                           .str.replace(r'\\W', ' ')\n",
    "                           .str.lower()\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            SMS\n",
       "0   ham                   yep  by the pretty sculpture\n",
       "1   ham  yes  princess  are you going to make me moan "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a vocabulary list containing all of the unique words present in our data. We'll compare the words in each message to this list to calculate the probability that the message is spam or not using the equations stated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each message in the SMS column into a list of words\n",
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "\n",
    "# iterate over the SMS column and create a list of unique words\n",
    "vocabulary = []\n",
    "for message in training_set['SMS']:\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            pass\n",
    "        else:\n",
    "            vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use the vocabulary list to make the data transformation described above (transform the SMS column to a series of columns).\n",
    "\n",
    "To make the transformation, we'll first build a dictionary that contains the information on how many times each unique word appears in each message. Then, we'll create a new dataframe out of that dictionary and join it with the `training_set` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary containing zero counts for all words\n",
    "word_counts_per_message = {unique_word: [0] * len(training_set['SMS'])\n",
    "                           for unique_word in vocabulary}\n",
    "\n",
    "# fill the dictionary with the proper counts per word\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_message[word][index] += 1\n",
    "        \n",
    "# transform the dictionary into a dataframe\n",
    "word_counts_per_message = pd.DataFrame(word_counts_per_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>are</th>\n",
       "      <th>you</th>\n",
       "      <th>going</th>\n",
       "      <th>...</th>\n",
       "      <th>beauty</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   yep  by  the  pretty  sculpture  yes  princess  are  you  going  ...  \\\n",
       "0    1   1    1       1          1    0         0    0    0      0  ...   \n",
       "1    0   0    0       0          0    1         1    1    1      1  ...   \n",
       "2    0   0    0       0          0    0         0    0    0      0  ...   \n",
       "3    0   0    0       0          0    0         0    0    0      0  ...   \n",
       "4    0   0    0       0          0    0         0    0    0      0  ...   \n",
       "\n",
       "   beauty  hides  secrets  n8  jewelry  related  trade  arul  bx526  wherre  \n",
       "0       0      0        0   0        0        0      0     0      0       0  \n",
       "1       0      0        0   0        0        0      0     0      0       0  \n",
       "2       0      0        0   0        0        0      0     0      0       0  \n",
       "3       0      0        0   0        0        0      0     0      0       0  \n",
       "4       0      0        0   0        0        0      0     0      0       0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_message.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the new dataframe with the training_set dataframe\n",
    "training_set_final = pd.concat([training_set, word_counts_per_message],\n",
    "                               axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>beauty</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  yep  by  the  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]    1   1    1   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...    0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]    0   0    0   \n",
       "3   ham                                           [havent]    0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0   0    0   \n",
       "\n",
       "   pretty  sculpture  yes  princess  are  ...  beauty  hides  secrets  n8  \\\n",
       "0       1          1    0         0    0  ...       0      0        0   0   \n",
       "1       0          0    1         1    1  ...       0      0        0   0   \n",
       "2       0          0    0         0    0  ...       0      0        0   0   \n",
       "3       0          0    0         0    0  ...       0      0        0   0   \n",
       "4       0          0    0         0    0  ...       0      0        0   0   \n",
       "\n",
       "   jewelry  related  trade  arul  bx526  wherre  \n",
       "0        0        0      0     0      0       0  \n",
       "1        0        0      0     0      0       0  \n",
       "2        0        0      0     0      0       0  \n",
       "3        0        0      0     0      0       0  \n",
       "4        0        0      0     0      0       0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Spam Filter\n",
    "Now that we're done with data cleaning and have a training set to work with, we can begin creating the spam filter. \n",
    "\n",
    "### Calculating the Constants\n",
    "Recall the equations we'll be using for the filter:\n",
    "\n",
    "$$ P(\\textrm{Spam}|w_1,w_2,\\ldots,w_n) \\propto P(\\textrm{Spam}) \\cdot \\prod_{i=1}^{n} P(w_i|\\textrm{Spam}) $$\n",
    "\n",
    "$$ P(\\textrm{Ham}|w_1,w_2,\\ldots, w_n) \\propto P(\\textrm{Ham}) \\cdot \\prod_{i=1}^{n} P(w_i|\\textrm{Ham}) $$\n",
    "\n",
    "Where $P(w_i|\\textrm{Spam})$ and $P(w_i|\\textrm{Ham})$ are given by:\n",
    "\n",
    "$$ P(w_i|\\textrm{Spam}) = \\frac{N_{w_i|\\textrm{Spam}} + \\alpha}{N_{\\textrm{Spam}} + \\alpha \\cdot N_{\\textrm{Vocabulary}}} $$\n",
    "\n",
    "$$ P(w_i|\\textrm{Ham}) = \\frac{N_{w_i|\\textrm{Ham}} + \\alpha}{N_{\\textrm{Ham}} + \\alpha \\cdot N_{\\textrm{Vocabulary}}} $$\n",
    "\n",
    "The following terms are constants in these equations that we can calculate now and have at the ready:\n",
    "* $P(\\textrm{Spam})$ (the probability that a message is spam)\n",
    "* $P(\\textrm{Ham})$ (the probability that a message is not spam)\n",
    "* $N_{\\textrm{Spam}}$ (number of words in all of the spam messages)\n",
    "* $N_{\\textrm{Ham}}$ (number of words in all of the ham messages)\n",
    "* $N_{\\textrm{Vocabulary}}$ (number of unique words in all messages)\n",
    "* Set smoothing factor to $\\alpha = 1$ (Laplace Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate spam and ham messages\n",
    "n_messages = training_set_final.shape[0]\n",
    "hams = training_set_final[training_set_final['Label']=='ham']\n",
    "spams = training_set_final[training_set_final['Label']=='spam']\n",
    "\n",
    "# calculate P(Spam) and P(Ham)\n",
    "p_spam = spams.shape[0] / n_messages\n",
    "p_ham = hams.shape[0] / n_messages\n",
    "\n",
    "# calculate N_spam\n",
    "n_spam = spams['SMS'].apply(len).sum()\n",
    "    \n",
    "# calculate N_hamf\n",
    "n_ham = hams['SMS'].apply(len).sum()\n",
    "\n",
    "# calculate N_vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Parameters\n",
    "We've got our $P(\\textrm{Spam}), P(\\textrm{Ham}), N_{\\textrm{Spam}}, N_{\\textrm{Ham}}, N_{\\textrm{Vocabulary}}$ and $\\alpha$, which will remain constant regardless of the message.\n",
    "\n",
    "Now, we'll need to calculate $P(w_i|\\textrm{Spam})$ and $P(w_i|\\textrm{Ham})$, which vary depending on the individual words. We can use our training set to calculate the probabilities, $P(w_i|\\textrm{Spam})$ and $P(w_i|\\textrm{Ham})$, for each word in our vocabulary. These probability values are called parameters.\n",
    "\n",
    "We'll use equations below to calculate the probabilities for each word:\n",
    "\n",
    "$$ P(w_i|\\textrm{Spam}) = \\frac{N_{w_i|\\textrm{Spam}} + \\alpha}{N_{\\textrm{Spam}} + \\alpha \\cdot N_{\\textrm{Vocabulary}}} $$\n",
    "\n",
    "$$ P(w_i|\\textrm{Ham}) = \\frac{N_{w_i|\\textrm{Ham}} + \\alpha}{N_{\\textrm{Ham}} + \\alpha \\cdot N_{\\textrm{Vocabulary}}} $$\n",
    "\n",
    "First, we'll initialize two dictionaries, where each key-value pair is a unique word (from our vocabulary) represented as a string, and the value is 0. One dictionary will store the parameters for $P(w_i|\\textrm{Spam})$ and the other will store the parameteres for $P(w_i|\\textrm{Ham})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionaries for P(w_i|Spam) and P(w_i|Ham)\n",
    "param_spam = {unique_word: 0 for unique_word in vocabulary}\n",
    "param_ham = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "# calculate parameters\n",
    "for word in vocabulary:\n",
    "    # get N_(w_i|Spam) and N_(w_i|Ham) for the current word\n",
    "    n_wispam = spams[word].sum()\n",
    "    n_wiham = hams[word].sum()\n",
    "    # calculate P(w_i|Spam) and P(w_i|Ham)\n",
    "    p_word_spam = (n_wispam + alpha) / ((n_spam + alpha) * n_vocabulary)\n",
    "    p_word_ham = (n_wiham + alpha) / ((n_ham + alpha) * n_vocabulary)\n",
    "    # assign value to key in dictionaries\n",
    "    param_spam[word] = p_word_spam\n",
    "    param_ham[word] = p_word_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Spam Filter\n",
    "Now that we've calculated all the constants and parameters we need, we can finally start creating the spam filter. The spam filter can be understood as a function that:\n",
    "* Takes in as input a new message ($w_1, w_2, \\ldots, w_n$)\n",
    "* Calculates $P(\\textrm{Spam}|w_1, w_2, \\ldots, w_n)$ and $P(\\textrm{Ham}|w_1, w_2, \\ldots, w_n)$\n",
    "* Compares the values of $P(\\textrm{Spam}|w_1, w_2, \\ldots, w_n)$ and $P(\\textrm{Ham}|w_1, w_2, \\ldots, w_n)$ and:\n",
    "    * If $P(\\textrm{Ham}|w_1, w_2, \\ldots, w_n)$ > $P(\\textrm{Spam}|w_1, w_2, \\ldots, w_n)$, then the message is classified as ham.\n",
    "    * If $P(\\textrm{Ham}|w_1, w_2, \\ldots, w_n)$ < $P(\\textrm{Spam}|w_1, w_2, \\ldots, w_n)$, then the message is classified as spam.\n",
    "    * If $P(\\textrm{Ham}|w_1, w_2, \\ldots, w_n)$ = $P(\\textrm{Spam}|w_1, w_2, \\ldots, w_n)$, then the algorithm may request human help.\n",
    "    \n",
    "Below, we'll create this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    '''This function will classify an input message as either\n",
    "    spam or not spam.'''\n",
    "    # clean the message and transform it into a list of words\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "\n",
    "    # initiate probabilities\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # iterate over each word in the message and calculate probability value\n",
    "    for word in message:\n",
    "        if word in param_spam:\n",
    "            p_spam_given_message *= param_spam[word]\n",
    "        if word in param_ham:\n",
    "            p_ham_given_message *= param_ham[word]\n",
    "    \n",
    "    print('P(Spam|message): {}'.format(p_spam_given_message))\n",
    "    print('P(Ham|message): {}'.format(p_ham_given_message))\n",
    "    \n",
    "    # classify the message\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities, have a human classify this :(')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this function with one spam message and one ham message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Message Test:\n",
      "P(Spam|message): 5.32218937227696e-59\n",
      "P(Ham|message): 5.821370428319695e-62\n",
      "Label: Spam\n",
      "\n",
      "Ham Message Test:\n",
      "P(Spam|message): 2.5485202709195435e-51\n",
      "P(Ham|message): 5.2028823344528615e-48\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "message_spam = 'WINNER!! This is the secret code to unlock the money: C3421'\n",
    "message_ham = 'Sounds good, Tom, then see u there'\n",
    "\n",
    "print('Spam Message Test:')\n",
    "classify(message_spam)\n",
    "\n",
    "print('\\nHam Message Test:')\n",
    "classify(message_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classification function seems to work.\n",
    "\n",
    "## Measuring the Accuracy of the Spam Filter\n",
    "Now that we have a working spam filter, we'll apply it to our test set and measure its accuracy using\n",
    "\n",
    "$$ \\textrm{Accuracy} = \\frac{\\textrm{number of correctly classified messages}}{\\textrm{total number of classified messages}} $$\n",
    "\n",
    "To make things easier, we'll create a new column in `test_set`, named `predicted`, that will show the results of our classification function for each message in the data set. Then, we'll count the number of correctly classified messages and apply it to the equation above.\n",
    "\n",
    "To apply our function to the test set, we'll need to alter the function so that it returns the labels instead of printing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    '''This function will classify an input message as either\n",
    "    spam or not spam.'''\n",
    "    # clean the message and transform it into a list of words\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "\n",
    "    # initiate probabilities\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # iterate over each word in the message and calculate probability value\n",
    "    for word in message:\n",
    "        if word in param_spam:\n",
    "            p_spam_given_message *= param_spam[word]\n",
    "        if word in param_ham:\n",
    "            p_ham_given_message *= param_ham[word]\n",
    "    \n",
    "    # classify the message\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'need human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to the test set and create the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll count the number of correctly classified messages and calculate our function's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1078\n",
      "Incorrect: 36\n",
      "Accuracy: 0.9676840215439856\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "\n",
    "# count correct classifications\n",
    "for index, row in test_set.iterrows():\n",
    "    if row[0] == row[2]:\n",
    "        correct += 1\n",
    "        \n",
    "# calculate the accuracy\n",
    "accuracy = correct / total\n",
    "\n",
    "print('Correct: {}'.format(correct))\n",
    "print('Incorrect: {}'.format(total - correct))\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification function that we created is accurate about 96.8% of the time. Out of 1,114 new messages, our filter was able to correctly classify 1,078 of them.\n",
    "\n",
    "## Conclusions\n",
    "Recall that our goal for this project was to create a spam filter using the multinomial Naive Bayes algorithm with at least 80% accuracy. We managed to create a spam filter with an accuracy of 96.77% on the test set, which greatly exceeds our initial standard of 80% accuracy. To further improve our spam filter, we can:\n",
    "* Investigate the 36 incorrectly classified messages and figure out why the algorithm reached the wrong conclusions.\n",
    "* Make the filtering process more complex by making the algorithm case-sensitive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
